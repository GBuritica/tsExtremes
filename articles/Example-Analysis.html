<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="tsExtremes">
<title>Section 1: Tail-index inference • tsExtremes</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/Roboto-0.4.9/font.css" rel="stylesheet">
<link href="../deps/JetBrains_Mono-0.4.9/font.css" rel="stylesheet">
<link href="../deps/Roboto_Slab-0.4.9/font.css" rel="stylesheet">
<!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.11/clipboard.min.js" integrity="sha512-7O5pXpc0oCRrxk8RUfDYFgn0nO1t+jLuIOQdOMRp4APB7uZ4vSjspzp5y6YDtDs4VzUSTbWzBFZ/LKJhnyFOKw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Section 1: Tail-index inference">
<meta property="og:description" content="tsExtremes">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=%7BG-03X4DCM0HF%7D"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', '{G-03X4DCM0HF}');
</script>
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light" data-bs-theme="light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">tsExtremes</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.0.1</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../articles/tsExtremes.html">Get started</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/Cluster-functional-Analysis.html">Section 2: Cluster inference</a>
    <a class="dropdown-item" href="../articles/Example-Analysis.html">Section 1: Tail-index inference</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/GBuritica/tsExtremes/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Section 1: Tail-index inference</h1>
                        <h4 data-toc-skip class="author">Gloria
Buriticá</h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/GBuritica/tsExtremes/blob/HEAD/vignettes/articles/Example-Analysis.Rmd" class="external-link"><code>vignettes/articles/Example-Analysis.Rmd</code></a></small>
      <div class="d-none name"><code>Example-Analysis.Rmd</code></div>
    </div>

    
    
<style>
p.comment{
background-color: #E3E7F1;
padding: 10px;
border: 1px solid black;
margin-left: 25px;
border-radius: 5px;
font-style: italic;
}



</style>
<div class="section level3">
<h3 id="main-goals-of-this-tutorial">Main goals of this tutorial<a class="anchor" aria-label="anchor" href="#main-goals-of-this-tutorial"></a>
</h3>
<ol style="list-style-type: decimal">
<li>Review heavy-tailed random variables.</li>
<li>Compute estimates of the tail index.</li>
</ol>
<p>The tail-index <span class="math inline">\(\alpha &gt; 0\)</span> of
a heavy-tailed random variable <span class="math inline">\(X\)</span> is
associated with the magnitude of rare events, in this section we review
a definition of heavy-tailed variables. The tail-index is a key
statistic in risk assessment applications because it measures the
magnitude of extremes. Roughly speaking, when <span class="math inline">\(\alpha\)</span> is small, the extremes are highly
significant, and from a practical perspective, this translates to
high-impact consequences. For example, in hydrology heavy precipitation
amounts lead to devastating losses. To sum up, if <span class="math inline">\(\alpha\)</span> is small, extremely high records
are more likely to happen than if <span class="math inline">\(\alpha\)</span> is large.</p>
</div>
<div class="section level3">
<h3 id="heavy-tailed-random-variables">Heavy-tailed random variables<a class="anchor" aria-label="anchor" href="#heavy-tailed-random-variables"></a>
</h3>
<p>In our setting, we consider a real-valued random variable <span class="math inline">\(X\)</span> and we say it is heavy-tailed when its
tail distribution has a polynomial decay. To fomalize this definition we
introduce the concept of regular variation. <br><br></p>
<p class="comment">
<strong>Definition.</strong> (Regular variation) We say that a real
valued random variable <span class="math inline">\(X\)</span> with
distribution <span class="math inline">\(F\)</span> is regularly varying
with <strong>tail-index</strong> <span class="math inline">\(\alpha &gt;
0\)</span> if <span class="math inline">\(\lim_{t \to \infty}\bar
F(tx)/\bar F(t) = x^{-\alpha},\)</span> where <span class="math inline">\(\bar F(t) := 1- F(t)\)</span> is the tail
distribution.
</p>
<p>
</p>
<p>In the following we call heavy-tailed variables those with regularly
varying distributions.</p>
<p><strong>Examples of heavy-tailed variables</strong> are the Pareto
random variables, the Fréchet, the <span class="math inline">\(t-\)</span>student, the Burr or the log Gamma
distribution.</p>
<p><strong>Examples of light-tailed distributions</strong> include then
the exponential, the Weibull and the gaussian distribution. For these
light-tailed examples, its tail distributions decay at an exponential
rate and not at a polynomial rate as for regularly varying distribution.
In practice this means that is very rare to record high levels sampling
from them, and instead the values concentrate around the mean.</p>
<div class="section level4">
<h4 id="moments-of-regularly-varying-distributions">Moments of regularly varying distributions<a class="anchor" aria-label="anchor" href="#moments-of-regularly-varying-distributions"></a>
</h4>
<p>In the case of regularly varying random variables, the variance and
the mean can sometimes equal infinity. This means that sampling from
this variable, we obtain highly scattered observations reaching higher
records in comparison with light-tailed distributions. To see this
consider the following samples, and its respective boxplot.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://www.stat.auckland.ac.nz/~yee/VGAM/" class="external-link">VGAM</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org" class="external-link">ggplot2</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">n</span>     <span class="op">&lt;-</span> <span class="fl">500</span></span>
<span><span class="va">alpha</span> <span class="op">&lt;-</span> <span class="fl">2</span></span>
<span><span class="va">sample_exponential</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html" class="external-link">rexp</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span><span class="va">sample_pareto</span>      <span class="op">&lt;-</span> <span class="fu">VGAM</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/VGAM/man/ParetoUC.html" class="external-link">rpareto</a></span><span class="op">(</span><span class="va">n</span>, shape<span class="op">=</span><span class="va">alpha</span><span class="op">)</span></span></code></pre></div>
<p><img src="Example-Analysis_files/figure-html/scattered%20observations%20plot-1.png" width="384" style="display: block; margin: auto;"></p>
<p>As we already mentioned, the tail index of a heavy-tailed random
variable plays an important role in determining the heaviness of
tails.</p>
<p><strong>Moments’ property: </strong> If <span class="math inline">\(X\)</span> is non-negative and regularly varying
with index <span class="math inline">\(\alpha &gt; 0\)</span>, then for
<span class="math inline">\(p &gt; \alpha\)</span>, <span class="math inline">\(E[X^p] = + \infty\)</span>, and for <span class="math inline">\(p &lt; \alpha\)</span>, <span class="math inline">\(E[X^p] &lt; + \infty\)</span>.</p>
<p>In particular the moments’ property entails that for <span class="math inline">\(\alpha \in (0,2)\)</span>, the variance of the
variable <span class="math inline">\(X\)</span> is infinite and for
<span class="math inline">\(\alpha \in (0,1)\)</span> its mean is
infinite. In other words, small values of <span class="math inline">\(\alpha\)</span> indicate heavier tails than larger
values of <span class="math inline">\(\alpha\)</span>. For these
reasons, estimating the tail-index of a random variable <span class="math inline">\(X\)</span> is important to quantify the magnitude
of rare events. For a full overview on regularly varying distributions
we refer to <span class="citation">(Bingham, Goldie, and Teugels
1987)</span>.</p>
</div>
</div>
<div class="section level3">
<h3 id="inference-of-the-tail-index">Inference of the tail-index<a class="anchor" aria-label="anchor" href="#inference-of-the-tail-index"></a>
</h3>
<p>In this subsection we now turn to the problem of esimating the
tail-index from data. We consider a sample of observations <span class="math inline">\(X_1, \dots, X_n\)</span> with the same
distribution of <span class="math inline">\(X\)</span>, and not
necessarily independent.</p>
<div class="section level4">
<h4 id="motivation">Motivation<a class="anchor" aria-label="anchor" href="#motivation"></a>
</h4>
<p>To motivate the Hill estimator, note that when <span class="math inline">\(P\)</span> follows the Pareto distribution with
tail index <span class="math inline">\(\alpha\)</span>, then <span class="math inline">\(\mathbb{P}(Y &gt; x) = 1 -x^{-\alpha}\)</span>,
and then straightforward calculations imply <span class="math display">\[E[\log(P)] = \frac{1}{\alpha}.\]</span> In all
generality, when <span class="math inline">\(X\)</span> is regularly
varying, then for all <span class="math inline">\(x &gt; 1\)</span>,
<span class="math display">\[
\lim_{t \to \infty}\mathbb{P}(X/t &gt; x \mid X &gt; t) = \lim_{t \to
\infty} {\overline F(tx)}/{\overline F(t) } = x^{-\alpha}.
\]</span> where the last equality follows by the definition of regularly
varying random variables. We can interpret this equation to say that the
renormalized sample exceeded amount follows asymptotically a Pareto
distribution. In this sense <span class="math display">\[\mathbb{E}[
\log(X/t) | X &gt; t] \approx \frac{1}{\alpha}, \qquad t \to \infty.
\]</span> Finally, replacing the right-hand side in the previous
relation with its empirical counterpart yields <span class="math display">\[
\frac{ \sum_{j=1}^n \log(X_j/t)1(X_j &gt; t)}{\sum_{j=1}^n 1(X_j&gt; t)}
\approx \frac{1}{\alpha}, \qquad t \to \infty.
\]</span></p>
<p>Here the value of <span class="math inline">\(t\)</span> is a high
threshold of the sample. In our case, we replace <span class="math inline">\(t\)</span> by an order statistic of the sample. If
<span class="math inline">\(X_{(1)} \geq X_{(2)} \geq \cdots \geq
X_{(n)}\)</span> are the sorted sample values, then we see that letting
<span class="math inline">\(t = X_{(k^\prime+1)}\)</span> is the
previous expression we obtain the Hill estimator</p>
<p class="comment">
<strong>Hill estimator.</strong> The Hill estimator is a general
procedure to estimate the tail-index of <span class="math inline">\(X\)</span>, and it is given by <span class="math display">\[
\frac{1}{\widehat{\alpha}^n} \;  :=
\;  \frac{1}{\widehat{\alpha}^n(k^\prime)}  := \frac{1}{k^\prime} \,
\sum_{t=1}^{n} \log(X_t/X_{(k^\prime+1)})1(X_t &gt; X_{(k^\prime +1)}),
\]</span> where <span class="math inline">\(X_{(1)} \geq X_{(2)} \geq
\dots \geq  X_{(n)}\)</span> are the sorted sample records, and <span class="math inline">\(k^\prime\)</span> is a tuning parameter for the
Hill estimator.
</p>
<p>
</p>
<p>We see from the previous expression that the assumption of regular
variation means that the top records from the sample: <span class="math inline">\(X_{(1)} \geq \cdots \geq X_{(k^\prime)}\)</span>,
resemble a sample from a Pareto distribution with tail-index <span class="math inline">\(\alpha &gt; 0\)</span>.</p>
<p>Finally, the Hill estimator yields consistent estimates of the
tail-index of <span class="math inline">\(X\)</span> even when the
temporal dependence is not very strong, think for example in a
stationary AR(1) series: <span class="math inline">\(X_t = \rho X_{t-1}
+ Z_{t}\)</span>, for <span class="math inline">\(|\rho| &lt;
1\)</span>, and <span class="math inline">\((\mathbb{Z})\)</span> a
series of iid regularly varying innovations. We refer to Chapter 4 in
<span class="citation">(Beirlant et al. 2004)</span> for a detailed
treatment of tail-index inference.</p>
</div>
<div class="section level4">
<h4 id="bias-variance-trade-off">Bias-Variance trade-off<a class="anchor" aria-label="anchor" href="#bias-variance-trade-off"></a>
</h4>
<p>The Hill estimator requires the tuning parameter <span class="math inline">\(k^\prime\)</span> in its implementation, and this
choice highlights the classical bias-variance trade-off in extreme value
statistics. Larger values of <span class="math inline">\(k^\prime\)</span> mean that when we average a
larger number of sample records to compute the Hill estimate, which
typically translates in a variance reduction for this statistical
procedure. Nevertheless, to obtain unbiased estimates of the tail-index
it is important that our top records: <span class="math inline">\(X_{(1)} \geq \cdots \geq X_{(k^\prime)}\)</span>
nicely resemble a sample from a Pareto distribution with tail-index
<span class="math inline">\(\alpha\)</span>. However, in all generality
this is only granted in many cases if <span class="math inline">\(k^\prime = k_n^\prime\)</span> is rather small
compared to <span class="math inline">\(n\)</span>, which means we can
only focus on the top records.</p>
<p><strong>qq-plot</strong> : To illustrate the bias-variance trade-off,
let’s take again <span class="math inline">\(P\)</span> to be a Pareto
distribution. Moreover notice that for all <span class="math inline">\(p
\in (0,1)\)</span>, the quantiles of <span class="math inline">\(\log
P\)</span> can be computed noticing <span class="math inline">\(\mathbb{P}(\log(P) &gt;  - \log(p)/\alpha ) =
\mathbb{P}(P &gt; p^{-1/\alpha} ) = p.\)</span> This equation
demonstrates that the qq-plot of sample from <span class="math inline">\(\log(P)\)</span> is given by the points <span class="math display">\[ (\log(P_{(k)}),-\log(1-k/n)/\alpha),\]</span>
where again recall the notation <span class="math inline">\(P_{(1)} \geq
\cdots P_{(n)}\)</span>. Instead, for a general regularly varying
variables <span class="math inline">\(X\)</span>, when we plot <span class="math inline">\((\log(X_{(k)}),-\log(1-k/n)/\alpha))\)</span>,
then only the highest records of the sample should align with the
quantiles of <span class="math inline">\(\log P\)</span>.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://rpkgs.datanovia.com/ggpubr/" class="external-link">ggpubr</a></span><span class="op">)</span></span>
<span><span class="va">sample_frechet</span>     <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/VGAM/man/frechetUC.html" class="external-link">rfrechet</a></span><span class="op">(</span><span class="va">n</span>, shape <span class="op">=</span> <span class="va">alpha</span><span class="op">)</span></span>
<span><span class="va">sample_pareto</span>      <span class="op">&lt;-</span> <span class="fu">VGAM</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/VGAM/man/ParetoUC.html" class="external-link">rpareto</a></span><span class="op">(</span><span class="va">n</span>, shape<span class="op">=</span><span class="va">alpha</span><span class="op">)</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span><span class="st">'log_frechet'</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sort.html" class="external-link">sort</a></span><span class="op">(</span><span class="va">sample_frechet</span><span class="op">)</span><span class="op">)</span>, </span>
<span>                  <span class="st">'log_pareto'</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sort.html" class="external-link">sort</a></span><span class="op">(</span><span class="va">sample_pareto</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">g1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="external-link">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span> y <span class="op">=</span> <span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="fl">1</span><span class="op">:</span><span class="va">n</span><span class="op">/</span><span class="va">n</span><span class="op">)</span><span class="op">/</span><span class="va">alpha</span>, x <span class="op">=</span> <span class="va">log_pareto</span> <span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html" class="external-link">geom_abline</a></span><span class="op">(</span>slope<span class="op">=</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">g2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="external-link">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span> y <span class="op">=</span> <span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="fl">1</span><span class="op">:</span><span class="va">n</span><span class="op">/</span><span class="va">n</span><span class="op">)</span><span class="op">/</span><span class="va">alpha</span>, x <span class="op">=</span> <span class="va">log_frechet</span> <span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html" class="external-link">geom_abline</a></span><span class="op">(</span>slope<span class="op">=</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rpkgs.datanovia.com/ggpubr/reference/ggarrange.html" class="external-link">ggarrange</a></span><span class="op">(</span><span class="va">g1</span>,<span class="va">g2</span><span class="op">)</span></span></code></pre></div>
<p><img src="Example-Analysis_files/figure-html/qqplot-1.png" width="576" style="display: block; margin: auto;"></p>
<p>Finally, as expected we can see from the plot above that when <span class="math inline">\(X\)</span> follows the Fréchet distributions, then
only the <span class="math inline">\(k^\prime\)</span>-largest sample
records can be accurately modeled using a Pareto distribution. From this
plot we take that in this case we need to choose <span class="math inline">\(k^\prime = k_n^\prime\)</span> from the Hill
estimator rather small compared to <span class="math inline">\(n\)</span> to satisfactorily describe the tail
properties of the variable <span class="math inline">\(X\)</span>.</p>
</div>
</div>
<div class="section level3">
<h3 id="tsextremes-package-implementation">tsExtremes package implementation<a class="anchor" aria-label="anchor" href="#tsextremes-package-implementation"></a>
</h3>
<div class="section level4">
<h4 id="hill-estimator">Hill estimator<a class="anchor" aria-label="anchor" href="#hill-estimator"></a>
</h4>
<p>We are now ready to use the tsExtremes package to compute Hill
estimates of the tail-index. We start by loading the <span class="math inline">\(\texttt{tsExtremes}\)</span> package.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/GBuritica/tsExtremes" class="external-link">tsExtremes</a></span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">h</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/hillestimator.html">hillestimator</a></span><span class="op">(</span><span class="va">sample_pareto</span>, plot<span class="op">=</span><span class="cn">T</span> , k1<span class="op">=</span><span class="fl">1</span><span class="op">:</span><span class="fl">500</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html" class="external-link">abline</a></span><span class="op">(</span>h<span class="op">=</span><span class="fl">1</span><span class="op">/</span><span class="va">alpha</span><span class="op">)</span></span></code></pre></div>
<p><img src="Example-Analysis_files/figure-html/unbiased-hill-1.png" width="864" style="display: block; margin: auto;"></p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">h</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/hillestimator.html">hillestimator</a></span><span class="op">(</span><span class="va">sample_frechet</span>, plot<span class="op">=</span><span class="cn">T</span> , k1<span class="op">=</span><span class="fl">1</span><span class="op">:</span><span class="fl">500</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html" class="external-link">abline</a></span><span class="op">(</span>h<span class="op">=</span><span class="fl">1</span><span class="op">/</span><span class="va">alpha</span><span class="op">)</span></span></code></pre></div>
<p><img src="Example-Analysis_files/figure-html/unbiased-hill-2.png" width="864" style="display: block; margin: auto;">
We see that for the Fréchet sample it is important to choose the tuning
parameter relatively small to obtain nice estimates of the
tail-index.</p>
</div>
<div class="section level4">
<h4 id="unbiased-hill-estimator">Unbiased Hill estimator<a class="anchor" aria-label="anchor" href="#unbiased-hill-estimator"></a>
</h4>
<p>As we mentioned, the choice of <span class="math inline">\(k^\prime\)</span> is key to obtain unbiased
estimates of the tail-index. To choose <span class="math inline">\(k^\prime\)</span> one idea is to the previous
plot, so-called the Hill plot, and pick a value from a range where the
estimated values are steady as a function of <span class="math inline">\(k^\prime\)</span>. However, often in practice it
is not clear how to find this steady region when the estimator is very
unstable as a function of <span class="math inline">\(k^\prime\)</span>.
<span class="citation">(Haan, Mercadier, and Zhou 2016)</span> propose a
bias-correction methodology of the Hill-estimator which allows to obtain
Hill-based estimates that are more robust to the choice of the tuning
parameter. We compare both estimator in the following case study of
precipitation amounts. The <span class="math inline">\(\texttt{tsExtremes}\)</span> package includes the
rainfall dataset, containing daily rainfall records from nine different
weather stations in France. The data and season of each record is
available. To compute the tail-index and produce a Hill Plot of summer
rainfall in Brest we use the function below.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">h</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/alphaestimator.html">alphaestimator</a></span><span class="op">(</span><span class="va">rainfall</span><span class="op">$</span><span class="va">BREST</span><span class="op">[</span><span class="va">rainfall</span><span class="op">$</span><span class="va">SEASON</span><span class="op">==</span><span class="st">"SPRING"</span><span class="op">]</span>, plot<span class="op">=</span><span class="cn">T</span> , R0 <span class="op">=</span> <span class="fl">100</span>,  hill<span class="op">=</span><span class="cn">T</span> ,  k1 <span class="op">=</span> <span class="fl">300</span> <span class="op">)</span></span></code></pre></div>
<p><img src="Example-Analysis_files/figure-html/unbiased-hill-data-1.png" width="864" style="display: block; margin: auto;"></p>
<p>We see fro the plot that with the Hill estimator it is not very clear
how to choose the tuning parameter. Instead, the unbiased-Hill procedure
is stable over a wider range of values which facilitates chooing <span class="math inline">\(k^\prime\)</span>.</p>
</div>
</div>
<div class="section level2 unnumbered">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-beirlant:goegebeur:teugels:segers:dewaal:ferro:2004" class="csl-entry">
Beirlant, J., Y. Goegebeur, J. Teugels, J. Segers, D. de Waal, and Ferro
C. 2004. <em>Statistics of Extremes: Theory and Applications</em>. West
Sussex: John Wiley &amp; Sons.
</div>
<div id="ref-bingham:goldie:teugels:1987" class="csl-entry">
Bingham, N. H., C. M. Goldie, and J. L. Teugels. 1987. <em>Regular
Variation</em>. Cambridge: Cambridge University Press.
</div>
<div id="ref-dehaan:mercadier:zhou:2016" class="csl-entry">
Haan, L. de, G. Mercadier, and C. Zhou. 2016. <span>“Adapting Extreme
Value Statistics to Financial Time Series: Dealing Wih Bias and Serial
Dependence.”</span> <em>Finance and Stochastics</em> 20: 321–54.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Gloria Buriticá.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.9.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
